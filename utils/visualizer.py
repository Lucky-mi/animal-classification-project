"""
å¯è§†åŒ–æ¨¡å—
è´Ÿè´£äºº: B2 (Grad-CAM, t-SNE) + B3 (æ··æ·†çŸ©é˜µ, è®­ç»ƒæ›²çº¿)
åŠŸèƒ½: Grad-CAMçƒ­åŠ›å›¾ã€t-SNEé™ç»´å¯è§†åŒ–ã€æ··æ·†çŸ©é˜µã€è®­ç»ƒæ›²çº¿
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
import seaborn as sns
from typing import List, Optional, Tuple
import cv2
from sklearn.manifold import TSNE
from tqdm import tqdm
import os

# é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
def setup_chinese_font():
    """è®¾ç½®matplotlibä¸­æ–‡å­—ä½“"""
    import platform
    system = platform.system()

    if system == 'Windows':
        # Windowsç³»ç»Ÿä½¿ç”¨å¾®è½¯é›…é»‘æˆ–é»‘ä½“
        font_list = ['Microsoft YaHei', 'SimHei', 'SimSun']
    elif system == 'Darwin':
        # macOS
        font_list = ['Arial Unicode MS', 'PingFang SC', 'Heiti SC']
    else:
        # Linux
        font_list = ['WenQuanYi Micro Hei', 'Noto Sans CJK SC', 'DejaVu Sans']

    for font in font_list:
        try:
            matplotlib.rcParams['font.sans-serif'] = [font] + matplotlib.rcParams['font.sans-serif']
            matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
            break
        except:
            continue

# åˆå§‹åŒ–æ—¶è®¾ç½®å­—ä½“
setup_chinese_font()


class GradCAMVisualizer:
    """
    Grad-CAMå¯è§†åŒ–å™¨
    è®ºæ–‡: Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization (ICCV 2017)
    
    è´Ÿè´£äºº: B2
    åŠŸèƒ½: ç”Ÿæˆç±»æ¿€æ´»å›¾ï¼Œå±•ç¤ºæ¨¡å‹å…³æ³¨çš„åŒºåŸŸ
    """
    
    def __init__(self, model: nn.Module, target_layer: nn.Module, device: str = 'cuda'):
        """
        Args:
            model: è¦å¯è§†åŒ–çš„æ¨¡å‹
            target_layer: ç›®æ ‡å±‚ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€ä¸ªå·ç§¯å±‚ï¼‰
            device: è®¾å¤‡
        """
        self.model = model
        self.target_layer = target_layer
        self.device = device
        
        self.gradients = None
        self.activations = None
        
        # æ³¨å†Œhook
        self._register_hooks()
    
    def _register_hooks(self):
        """æ³¨å†Œå‰å‘å’Œåå‘hook"""
        def forward_hook(module, input, output):
            self.activations = output.detach()
        
        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0].detach()
        
        self.target_layer.register_forward_hook(forward_hook)
        self.target_layer.register_full_backward_hook(backward_hook)
    
    def generate_cam(self, image: torch.Tensor, target_class: Optional[int] = None) -> np.ndarray:
        """
        ç”Ÿæˆç±»æ¿€æ´»å›¾
        
        Args:
            image: è¾“å…¥å›¾åƒ [1, 3, H, W]
            target_class: ç›®æ ‡ç±»åˆ«ï¼ˆNoneåˆ™ä½¿ç”¨é¢„æµ‹ç±»åˆ«ï¼‰
        
        Returns:
            cam: ç±»æ¿€æ´»å›¾ [H, W]
        """
        self.model.eval()
        
        # å‰å‘ä¼ æ’­
        image = image.to(self.device)
        output = self.model(image)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç›®æ ‡ç±»åˆ«ï¼Œä½¿ç”¨é¢„æµ‹ç±»åˆ«
        if target_class is None:
            target_class = output.argmax(dim=1).item()
        
        # åå‘ä¼ æ’­
        self.model.zero_grad()
        output[0, target_class].backward()
        
        # è®¡ç®—æƒé‡ï¼šå…¨å±€å¹³å‡æ± åŒ–æ¢¯åº¦
        weights = self.gradients.mean(dim=[2, 3], keepdim=True)  # [1, C, 1, 1]
        
        # åŠ æƒæ±‚å’Œ
        cam = (weights * self.activations).sum(dim=1, keepdim=True)  # [1, 1, H, W]
        
        # ReLU
        cam = torch.relu(cam)
        
        # å½’ä¸€åŒ–åˆ°[0, 1]
        cam = cam.squeeze().cpu().numpy()
        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)
        
        return cam
    
    def visualize(
        self,
        image: torch.Tensor,
        original_image: np.ndarray,
        target_class: Optional[int] = None,
        alpha: float = 0.5
    ) -> np.ndarray:
        """
        å¯è§†åŒ–Grad-CAM
        
        Args:
            image: å½’ä¸€åŒ–åçš„è¾“å…¥å›¾åƒ [1, 3, H, W]
            original_image: åŸå§‹å›¾åƒ [H, W, 3], RGB, [0, 255]
            target_class: ç›®æ ‡ç±»åˆ«
            alpha: çƒ­åŠ›å›¾é€æ˜åº¦
        
        Returns:
            visualization: å åŠ åçš„å›¾åƒ [H, W, 3]
        """
        # ç”ŸæˆCAM
        cam = self.generate_cam(image, target_class)
        
        # è°ƒæ•´CAMå¤§å°åˆ°åŸå›¾å°ºå¯¸
        h, w = original_image.shape[:2]
        cam_resized = cv2.resize(cam, (w, h))
        
        # è½¬æ¢ä¸ºçƒ­åŠ›å›¾
        heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)
        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
        
        # å åŠ 
        visualization = heatmap * alpha + original_image * (1 - alpha)
        visualization = np.uint8(visualization)
        
        return visualization


def get_target_layer(model: nn.Module, model_name: str) -> nn.Module:
    """
    è·å–ç›®æ ‡å±‚ï¼ˆæœ€åä¸€ä¸ªå·ç§¯å±‚ï¼‰
    
    Args:
        model: æ¨¡å‹
        model_name: æ¨¡å‹åç§°
    
    Returns:
        target_layer: ç›®æ ‡å±‚
    """
    if model_name == 'resnet18':
        return model.layer4[-1]
    
    elif model_name == 'mobilenet_v2':
        return model.features[-1]
    
    elif model_name == 'deit_tiny':
        # Transformeræ²¡æœ‰å·ç§¯å±‚ï¼ŒGrad-CAMä¸é€‚ç”¨
        # å¯ä»¥ä½¿ç”¨Attention Rolloutç­‰æ–¹æ³•
        raise NotImplementedError("DeiT-Tinyä¸æ”¯æŒæ ‡å‡†Grad-CAMï¼Œè¯·ä½¿ç”¨Attentionå¯è§†åŒ–")
    
    else:
        raise ValueError(f"æœªçŸ¥æ¨¡å‹: {model_name}")


def plot_gradcam_comparison(
    models_dict: dict,
    image: torch.Tensor,
    original_image: np.ndarray,
    class_names: List[str],
    save_path: str
):
    """
    å¯¹æ¯”ä¸åŒæ¨¡å‹çš„Grad-CAM
    
    Args:
        models_dict: {'model_name': (model, target_layer)}
        image: å½’ä¸€åŒ–å›¾åƒ [1, 3, H, W]
        original_image: åŸå§‹å›¾åƒ [H, W, 3]
        class_names: ç±»åˆ«åç§°
        save_path: ä¿å­˜è·¯å¾„
    """
    num_models = len(models_dict)
    fig, axes = plt.subplots(1, num_models + 1, figsize=(5 * (num_models + 1), 5))
    
    # æ˜¾ç¤ºåŸå›¾
    axes[0].imshow(original_image)
    axes[0].set_title('Original Image', fontsize=14)
    axes[0].axis('off')
    
    # ä¸ºæ¯ä¸ªæ¨¡å‹ç”ŸæˆGrad-CAM
    for idx, (model_name, (model, target_layer)) in enumerate(models_dict.items(), 1):
        try:
            visualizer = GradCAMVisualizer(model, target_layer, device=image.device)
            vis = visualizer.visualize(image, original_image)
            
            axes[idx].imshow(vis)
            axes[idx].set_title(f'{model_name}', fontsize=14)
            axes[idx].axis('off')
        
        except Exception as e:
            print(f"âš ï¸ {model_name} Grad-CAMç”Ÿæˆå¤±è´¥: {e}")
            axes[idx].text(0.5, 0.5, f'Error: {model_name}', 
                          ha='center', va='center', transform=axes[idx].transAxes)
            axes[idx].axis('off')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ Grad-CAMå¯¹æ¯”å›¾ä¿å­˜è‡³: {save_path}")
    plt.close()


def visualize_tsne(
    model: nn.Module,
    data_loader,
    class_names: List[str],
    save_path: str,
    n_components: int = 2,
    perplexity: int = 30,
    device: str = 'cuda'
):
    """
    t-SNEç‰¹å¾å¯è§†åŒ–
    
    è´Ÿè´£äºº: B2
    åŠŸèƒ½: å°†é«˜ç»´ç‰¹å¾é™ç»´åˆ°2Dï¼Œå¯è§†åŒ–ä¸åŒç±»åˆ«çš„èšç±»æ•ˆæœ
    
    Args:
        model: æ¨¡å‹
        data_loader: æ•°æ®åŠ è½½å™¨
        class_names: ç±»åˆ«åç§°
        save_path: ä¿å­˜è·¯å¾„
        n_components: é™ç»´ç»´åº¦ï¼ˆ2æˆ–3ï¼‰
        perplexity: t-SNEçš„å›°æƒ‘åº¦å‚æ•°
        device: è®¾å¤‡
    """
    model.eval()
    
    features_list = []
    labels_list = []
    
    print("ğŸ” æå–ç‰¹å¾ç”¨äºt-SNE...")
    
    # æå–ç‰¹å¾ï¼ˆä»æœ€åä¸€å±‚å·ç§¯æˆ–å€’æ•°ç¬¬äºŒå±‚å…¨è¿æ¥ï¼‰
    def hook_fn(module, input, output):
        features_list.append(output.detach().cpu())
    
    # æ³¨å†Œhookåˆ°å€’æ•°ç¬¬äºŒå±‚
    if hasattr(model, 'fc'):
        # ResNet-18
        handle = model.avgpool.register_forward_hook(hook_fn)
    elif hasattr(model, 'classifier'):
        # MobileNetV2
        handle = model.features.register_forward_hook(hook_fn)
    else:
        raise NotImplementedError("ä¸æ”¯æŒçš„æ¨¡å‹ç»“æ„")
    
    with torch.no_grad():
        for images, labels in tqdm(data_loader, desc='Extracting features'):
            images = images.to(device)
            _ = model(images)
            labels_list.append(labels)
    
    handle.remove()
    
    # åˆå¹¶ç‰¹å¾
    features = torch.cat(features_list, dim=0)
    
    # å¦‚æœæ˜¯4Dç‰¹å¾å›¾ï¼Œè¿›è¡Œå…¨å±€å¹³å‡æ± åŒ–
    if len(features.shape) == 4:
        features = features.mean(dim=[2, 3])
    
    features = features.numpy()
    labels = torch.cat(labels_list, dim=0).numpy()
    
    print(f"ç‰¹å¾å½¢çŠ¶: {features.shape}")
    
    # t-SNEé™ç»´
    print(f"ğŸ§® æ‰§è¡Œt-SNEé™ç»´ (perplexity={perplexity})...")
    tsne = TSNE(n_components=n_components, perplexity=perplexity, random_state=42, verbose=1)
    features_2d = tsne.fit_transform(features)
    
    # å¯è§†åŒ–
    plt.figure(figsize=(10, 8))
    
    scatter = plt.scatter(
        features_2d[:, 0],
        features_2d[:, 1],
        c=labels,
        cmap='tab10',
        alpha=0.6,
        s=10
    )
    
    # æ·»åŠ å›¾ä¾‹
    handles, _ = scatter.legend_elements()
    plt.legend(handles, class_names, loc='best', fontsize=10)
    
    plt.title('t-SNE Visualization of Features', fontsize=16)
    plt.xlabel('t-SNE Dimension 1', fontsize=12)
    plt.ylabel('t-SNE Dimension 2', fontsize=12)
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ t-SNEå¯è§†åŒ–ä¿å­˜è‡³: {save_path}")
    plt.close()


def plot_confusion_matrix(
    conf_matrix: np.ndarray,
    class_names: List[str],
    save_path: str,
    normalize: bool = False,
    figsize: Tuple[int, int] = (10, 8)
):
    """
    ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    
    è´Ÿè´£äºº: B3
    
    Args:
        conf_matrix: æ··æ·†çŸ©é˜µ [num_classes, num_classes]
        class_names: ç±»åˆ«åç§°
        save_path: ä¿å­˜è·¯å¾„
        normalize: æ˜¯å¦å½’ä¸€åŒ–
        figsize: å›¾åƒå¤§å°
    """
    if normalize:
        conf_matrix = conf_matrix.astype('float') / conf_matrix.sum(axis=1)[:, np.newaxis]
        fmt = '.2f'
        title = 'Normalized Confusion Matrix'
    else:
        fmt = 'd'
        title = 'Confusion Matrix'
    
    plt.figure(figsize=figsize)
    
    sns.heatmap(
        conf_matrix,
        annot=True,
        fmt=fmt,
        cmap='Blues',
        xticklabels=class_names,
        yticklabels=class_names,
        cbar_kws={'label': 'Count' if not normalize else 'Proportion'}
    )
    
    plt.title(title, fontsize=16)
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ æ··æ·†çŸ©é˜µä¿å­˜è‡³: {save_path}")
    plt.close()


def plot_training_curves(
    history: dict,
    save_path: str,
    figsize: Tuple[int, int] = (15, 5)
):
    """
    ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    
    è´Ÿè´£äºº: B3
    
    Args:
        history: è®­ç»ƒå†å²ï¼ŒåŒ…å«train_loss, train_acc, val_loss, val_acc, lr
        save_path: ä¿å­˜è·¯å¾„
        figsize: å›¾åƒå¤§å°
    """
    epochs = range(1, len(history['train_loss']) + 1)
    
    fig, axes = plt.subplots(1, 3, figsize=figsize)
    
    # Lossæ›²çº¿
    axes[0].plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)
    axes[0].plot(epochs, history['val_loss'], 'r-', label='Val Loss', linewidth=2)
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss', fontsize=12)
    axes[0].set_title('Loss Curves', fontsize=14)
    axes[0].legend(fontsize=10)
    axes[0].grid(True, alpha=0.3)
    
    # Accuracyæ›²çº¿
    axes[1].plot(epochs, history['train_acc'], 'b-', label='Train Acc', linewidth=2)
    axes[1].plot(epochs, history['val_acc'], 'r-', label='Val Acc', linewidth=2)
    axes[1].set_xlabel('Epoch', fontsize=12)
    axes[1].set_ylabel('Accuracy (%)', fontsize=12)
    axes[1].set_title('Accuracy Curves', fontsize=14)
    axes[1].legend(fontsize=10)
    axes[1].grid(True, alpha=0.3)
    
    # Learning Rateæ›²çº¿
    axes[2].plot(epochs, history['lr'], 'g-', linewidth=2)
    axes[2].set_xlabel('Epoch', fontsize=12)
    axes[2].set_ylabel('Learning Rate', fontsize=12)
    axes[2].set_title('Learning Rate Schedule', fontsize=14)
    axes[2].set_yscale('log')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"ğŸ’¾ è®­ç»ƒæ›²çº¿ä¿å­˜è‡³: {save_path}")
    plt.close()


if __name__ == "__main__":
    print("å¯è§†åŒ–æ¨¡å—æµ‹è¯•éœ€è¦å®Œæ•´çš„æ¨¡å‹å’Œæ•°æ®")
    print("è¯·åœ¨å®éªŒè„šæœ¬ä¸­ä½¿ç”¨")