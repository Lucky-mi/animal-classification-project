"""
Animal-10 æ•°æ®é›†åŠ è½½å™¨
è´Ÿè´£äºº: B1
åŠŸèƒ½: ä»CSVæ–‡ä»¶è¯»å–æ•°æ®ï¼ŒåŠ è½½å›¾åƒï¼Œåº”ç”¨æ•°æ®å¢å¼º
"""

import os
import pandas as pd
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from typing import Callable, Optional, Tuple, Dict
import torch


class AnimalDataset(Dataset):
    """
    Animal-10 æ•°æ®é›†ç±»
    
    Args:
        root_dir: æ•°æ®é›†æ ¹ç›®å½•
        csv_file: CSVæ–‡ä»¶è·¯å¾„
        split: 'train', 'val', æˆ– 'test'
        transform: æ•°æ®å¢å¼ºå‡½æ•°
        class_to_idx: ç±»åˆ«åˆ°ç´¢å¼•çš„æ˜ å°„
    """
    
    def __init__(
        self,
        root_dir: str,
        csv_file: str,
        split: str = 'train',
        transform: Optional[Callable] = None,
        class_to_idx: Optional[Dict[str, int]] = None
    ):
        self.root_dir = root_dir
        self.split = split
        self.transform = transform
        
        # è¯»å–CSVæ–‡ä»¶
        csv_path = os.path.join(root_dir, csv_file)
        self.data = pd.read_csv(csv_path)
        
        # ç­›é€‰å¯¹åº”çš„split
        self.data = self.data[self.data['split'] == split].reset_index(drop=True)
        
        # åˆ›å»ºç±»åˆ«æ˜ å°„
        if class_to_idx is None:
            unique_labels = sorted(self.data['label'].unique())
            self.class_to_idx = {label: idx for idx, label in enumerate(unique_labels)}
        else:
            self.class_to_idx = class_to_idx
        
        self.idx_to_class = {idx: label for label, idx in self.class_to_idx.items()}
        self.classes = list(self.class_to_idx.keys())
        
        print(f"[{split.upper()}] åŠ è½½äº† {len(self.data)} å¼ å›¾åƒ")
        print(f"ç±»åˆ«æ˜ å°„: {self.class_to_idx}")
    
    def __len__(self) -> int:
        return len(self.data)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """
        è·å–ä¸€ä¸ªæ ·æœ¬
        
        Returns:
            image: å¢å¼ºåçš„å›¾åƒå¼ é‡
            label: ç±»åˆ«ç´¢å¼•
        """
        # è·å–å›¾åƒè·¯å¾„å’Œæ ‡ç­¾
        row = self.data.iloc[idx]
        img_name = row['path']  # CSVåˆ—åæ˜¯'path'è€Œé'filename'
        label_name = row['label']
        
        # æ„å»ºå®Œæ•´è·¯å¾„
        img_path = os.path.join(self.root_dir, img_name)
        
        # åŠ è½½å›¾åƒ
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"âš ï¸ åŠ è½½å›¾åƒå¤±è´¥: {img_path}, é”™è¯¯: {e}")
            # è¿”å›ä¸€ä¸ªé»‘è‰²å›¾åƒä½œä¸ºå¤‡ç”¨
            image = Image.new('RGB', (224, 224), (0, 0, 0))
        
        # åº”ç”¨æ•°æ®å¢å¼º
        if self.transform:
            image = self.transform(image)
        
        # è·å–æ ‡ç­¾ç´¢å¼•
        label = self.class_to_idx[label_name]
        
        return image, label
    
    def get_class_distribution(self) -> Dict[str, int]:
        """è·å–ç±»åˆ«åˆ†å¸ƒ"""
        return self.data['label'].value_counts().to_dict()


def get_dataloaders(
    root_dir: str,
    csv_file: str,
    train_transform: Callable,
    val_transform: Callable,
    batch_size: int = 32,
    num_workers: int = 4,
    pin_memory: bool = True
) -> Tuple[DataLoader, DataLoader, DataLoader, Dict[str, int]]:
    """
    åˆ›å»ºè®­ç»ƒã€éªŒè¯ã€æµ‹è¯•çš„DataLoader
    
    Args:
        root_dir: æ•°æ®é›†æ ¹ç›®å½•
        csv_file: CSVæ–‡ä»¶å
        train_transform: è®­ç»ƒé›†æ•°æ®å¢å¼º
        val_transform: éªŒè¯/æµ‹è¯•é›†æ•°æ®å¢å¼º
        batch_size: æ‰¹æ¬¡å¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        pin_memory: æ˜¯å¦ä½¿ç”¨pin_memoryåŠ é€Ÿ
    
    Returns:
        train_loader, val_loader, test_loader, class_to_idx
    """
    
    # å…ˆåˆ›å»ºè®­ç»ƒé›†ä»¥è·å–class_to_idx
    train_dataset = AnimalDataset(
        root_dir=root_dir,
        csv_file=csv_file,
        split='train',
        transform=train_transform
    )
    
    class_to_idx = train_dataset.class_to_idx
    
    # åˆ›å»ºéªŒè¯é›†å’Œæµ‹è¯•é›†
    val_dataset = AnimalDataset(
        root_dir=root_dir,
        csv_file=csv_file,
        split='val',
        transform=val_transform,
        class_to_idx=class_to_idx
    )
    
    test_dataset = AnimalDataset(
        root_dir=root_dir,
        csv_file=csv_file,
        split='test',
        transform=val_transform,
        class_to_idx=class_to_idx
    )
    
    # æ‰“å°ç±»åˆ«åˆ†å¸ƒ
    print("\nğŸ“Š ç±»åˆ«åˆ†å¸ƒ:")
    print(f"è®­ç»ƒé›†: {train_dataset.get_class_distribution()}")
    print(f"éªŒè¯é›†: {val_dataset.get_class_distribution()}")
    print(f"æµ‹è¯•é›†: {test_dataset.get_class_distribution()}")
    
    # åˆ›å»ºDataLoader
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True  # ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„batch
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory
    )
    
    return train_loader, val_loader, test_loader, class_to_idx


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    from augmentation import get_train_transform, get_val_transform
    
    train_transform = get_train_transform()
    val_transform = get_val_transform()
    
    train_loader, val_loader, test_loader, class_to_idx = get_dataloaders(
        root_dir="../../Animals-10",
        csv_file="train_test_val_split.csv",
        train_transform=train_transform,
        val_transform=val_transform,
        batch_size=8,
        num_workers=0
    )
    
    print(f"\nâœ… DataLoaderæµ‹è¯•æˆåŠŸï¼")
    print(f"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
    print(f"éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
    print(f"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}")
    
    # æµ‹è¯•ä¸€ä¸ªbatch
    images, labels = next(iter(train_loader))
    print(f"\næ‰¹æ¬¡å½¢çŠ¶: {images.shape}, æ ‡ç­¾å½¢çŠ¶: {labels.shape}")