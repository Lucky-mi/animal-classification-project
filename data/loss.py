"""
æŸå¤±å‡½æ•°æ¨¡å—
è´Ÿè´£äºº: B1
åŠŸèƒ½: å®ç°å¤šç§æŸå¤±å‡½æ•°ç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
- CrossEntropyLoss (åŸºçº¿)
- WeightedCrossEntropyLoss (åŠ æƒäº¤å‰ç†µ)
- FocalLoss (Focal Loss)
- WeightedFocalLoss (åŠ æƒFocal Loss) â­é‡ç‚¹
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Optional


class FocalLoss(nn.Module):
    """
    Focal Losså®ç°
    è®ºæ–‡: Focal Loss for Dense Object Detection (ICCV 2017)
    
    å…¬å¼: FL(p_t) = -Î±_t * (1-p_t)^Î³ * log(p_t)
    
    Args:
        alpha: ç±»åˆ«å¹³è¡¡å› å­ (None æˆ– Tensor[num_classes])
        gamma: èšç„¦å‚æ•°ï¼Œé€šå¸¸å–2.0
        reduction: 'none', 'mean', 'sum'
    """
    
    def __init__(
        self, 
        alpha: Optional[torch.Tensor] = None, 
        gamma: float = 2.0, 
        reduction: str = 'mean'
    ):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        Args:
            inputs: [batch_size, num_classes] æ¨¡å‹åŸå§‹è¾“å‡º (logits)
            targets: [batch_size] çœŸå®æ ‡ç­¾
        
        Returns:
            loss: æ ‡é‡æŸå¤±å€¼
        """
        # è®¡ç®—äº¤å‰ç†µï¼ˆä¸åšreductionï¼‰
        ce_loss = F.cross_entropy(inputs, targets, reduction='none')
        
        # è®¡ç®—é¢„æµ‹æ¦‚ç‡ p_t
        pt = torch.exp(-ce_loss)  # p_t = exp(-CE)
        
        # è®¡ç®—focalæƒé‡: (1-p_t)^Î³
        focal_weight = (1 - pt) ** self.gamma
        
        # è®¡ç®—focal loss
        focal_loss = focal_weight * ce_loss
        
        # å¦‚æœæä¾›äº†alphaï¼Œåº”ç”¨ç±»åˆ«å¹³è¡¡
        if self.alpha is not None:
            if self.alpha.device != inputs.device:
                self.alpha = self.alpha.to(inputs.device)
            
            # è·å–æ¯ä¸ªæ ·æœ¬å¯¹åº”ç±»åˆ«çš„alphaå€¼
            alpha_t = self.alpha[targets]
            focal_loss = alpha_t * focal_loss
        
        # Reduction
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss


class WeightedFocalLoss(nn.Module):
    """
    åŠ æƒFocal Lossï¼ˆç»“åˆç±»åˆ«æƒé‡å’ŒFocalæœºåˆ¶ï¼‰
    è¿™æ˜¯å®éªŒ2.5çš„æœ€ä½³æ–¹æ¡ˆ â­
    
    Args:
        class_weights: ç±»åˆ«æƒé‡ Tensor[num_classes]
        gamma: Focal Lossçš„Î³å‚æ•°
        reduction: 'none', 'mean', 'sum'
    """
    
    def __init__(
        self,
        class_weights: torch.Tensor,
        gamma: float = 2.0,
        reduction: str = 'mean'
    ):
        super(WeightedFocalLoss, self).__init__()
        self.class_weights = class_weights
        self.gamma = gamma
        self.reduction = reduction
    
    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:
        """
        Args:
            inputs: [batch_size, num_classes]
            targets: [batch_size]
        
        Returns:
            loss: æ ‡é‡æŸå¤±å€¼
        """
        # ä½¿ç”¨FocalLosså®ç°
        focal_loss = FocalLoss(alpha=self.class_weights, gamma=self.gamma, reduction=self.reduction)
        return focal_loss(inputs, targets)


def calculate_class_weights(class_counts: dict, method: str = 'inverse') -> torch.Tensor:
    """
    è®¡ç®—ç±»åˆ«æƒé‡
    
    Args:
        class_counts: ç±»åˆ«æ ·æœ¬æ•° {'cat': 2000, 'dog': 1500, ...}
        method: 'inverse' æˆ– 'effective'
    
    Returns:
        weights: Tensor[num_classes]
    
    ç¤ºä¾‹:
        class_counts = {'cat': 2000, 'dog': 1500, 'bird': 500}
        weights = calculate_class_weights(class_counts, method='inverse')
        # weights â‰ˆ [0.25, 0.33, 1.0] (å½’ä¸€åŒ–å)
    """
    # æŒ‰ç±»åˆ«åç§°æ’åºï¼ˆç¡®ä¿é¡ºåºä¸€è‡´ï¼‰
    sorted_classes = sorted(class_counts.keys())
    counts = torch.tensor([class_counts[c] for c in sorted_classes], dtype=torch.float32)
    
    if method == 'inverse':
        # åæ¯”ä¾‹: w_i = 1 / n_i
        weights = 1.0 / counts
        
    elif method == 'effective':
        # æœ‰æ•ˆæ ·æœ¬æ•°æ–¹æ³• (Class-Balanced Loss, CVPR 2019)
        # w_i = (1 - Î²) / (1 - Î²^n_i)
        beta = 0.9999
        weights = (1 - beta) / (1 - torch.pow(beta, counts))
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ–¹æ³•: {method}")
    
    # å½’ä¸€åŒ–æƒé‡ï¼ˆä½¿å¹³å‡æƒé‡ä¸º1ï¼‰
    weights = weights / weights.mean()
    
    print(f"\nğŸ“Š ç±»åˆ«æƒé‡ (method={method}):")
    for cls, weight in zip(sorted_classes, weights):
        print(f"  {cls}: {weight:.3f}")
    
    return weights


def get_loss_function(
    loss_type: str,
    class_counts: Optional[dict] = None,
    num_classes: int = 10,
    device: str = 'cuda'
) -> nn.Module:
    """
    è·å–æŸå¤±å‡½æ•°
    
    Args:
        loss_type: æŸå¤±å‡½æ•°ç±»å‹
            - 'ce': æ ‡å‡†äº¤å‰ç†µ
            - 'weighted_ce': åŠ æƒäº¤å‰ç†µ
            - 'focal': Focal Loss (Î³=2)
            - 'weighted_focal': åŠ æƒFocal Loss â­æ¨è
        class_counts: ç±»åˆ«æ ·æœ¬æ•°ç»Ÿè®¡
        num_classes: ç±»åˆ«æ•°é‡
        device: è®¾å¤‡
    
    Returns:
        criterion: æŸå¤±å‡½æ•°
    """
    
    if loss_type == 'ce':
        print("âœ… ä½¿ç”¨æ ‡å‡†äº¤å‰ç†µæŸå¤±")
        return nn.CrossEntropyLoss()
    
    elif loss_type == 'weighted_ce':
        if class_counts is None:
            raise ValueError("weighted_ceéœ€è¦æä¾›class_counts")
        
        weights = calculate_class_weights(class_counts, method='inverse')
        weights = weights.to(device)
        
        print("âœ… ä½¿ç”¨åŠ æƒäº¤å‰ç†µæŸå¤±")
        return nn.CrossEntropyLoss(weight=weights)
    
    elif loss_type == 'focal':
        print("âœ… ä½¿ç”¨Focal Loss (Î³=2.0)")
        return FocalLoss(alpha=None, gamma=2.0, reduction='mean')
    
    elif loss_type == 'weighted_focal':
        if class_counts is None:
            raise ValueError("weighted_focaléœ€è¦æä¾›class_counts")
        
        weights = calculate_class_weights(class_counts, method='inverse')
        weights = weights.to(device)
        
        print("âœ… ä½¿ç”¨åŠ æƒFocal Loss (Î³=2.0) â­æœ€ä½³æ–¹æ¡ˆ")
        return WeightedFocalLoss(class_weights=weights, gamma=2.0, reduction='mean')
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æŸå¤±å‡½æ•°ç±»å‹: {loss_type}")


if __name__ == "__main__":
    # æµ‹è¯•æŸå¤±å‡½æ•°
    print("=" * 50)
    print("æµ‹è¯•æŸå¤±å‡½æ•°æ¨¡å—")
    print("=" * 50)
    
    # æ¨¡æ‹Ÿæ•°æ®
    batch_size = 8
    num_classes = 10
    
    logits = torch.randn(batch_size, num_classes)
    targets = torch.randint(0, num_classes, (batch_size,))
    
    # æ¨¡æ‹Ÿç±»åˆ«ä¸å¹³è¡¡
    class_counts = {
        'butterfly': 2000,
        'cat': 1800,
        'chicken': 1500,
        'cow': 2200,
        'dog': 1900,
        'elephant': 800,   # å°‘æ•°ç±»
        'horse': 1700,
        'sheep': 1600,
        'spider': 900,     # å°‘æ•°ç±»
        'squirrel': 1000   # å°‘æ•°ç±»
    }
    
    # æµ‹è¯•æ‰€æœ‰æŸå¤±å‡½æ•°
    loss_types = ['ce', 'weighted_ce', 'focal', 'weighted_focal']
    
    for loss_type in loss_types:
        print(f"\n{'='*50}")
        criterion = get_loss_function(
            loss_type=loss_type,
            class_counts=class_counts if 'weighted' in loss_type else None,
            device='cpu'
        )
        
        loss = criterion(logits, targets)
        print(f"æŸå¤±å€¼: {loss.item():.4f}")
    
    print("\n" + "=" * 50)
    print("âœ… æ‰€æœ‰æŸå¤±å‡½æ•°æµ‹è¯•é€šè¿‡ï¼")
    print("=" * 50)