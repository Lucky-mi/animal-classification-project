"""
å®éªŒ6: é”™è¯¯æ ·æœ¬æ·±åº¦åˆ†æ (é‡ç‚¹å®éªŒ)
è´Ÿè´£äºº: B3
åŠŸèƒ½: æ·±å…¥åˆ†æè¢«é”™åˆ†çš„æ ·æœ¬ï¼Œæ‰¾å‡ºè§„å¾‹
ä½¿ç”¨æ–¹æ³•:
    python experiments/06_error_analysis.py --checkpoint ../outputs/exp2.5_imbalance/models/best_model.pth
"""

import os
import sys
sys.path.append('..')

import argparse
import torch
import yaml

from data import get_dataloaders, get_val_transform
from models import get_model
from utils import Evaluator, ErrorAnalyzer


def main(args):
    print(f"\n{'='*70}")
    print("ğŸ” å®éªŒ6: é”™è¯¯æ ·æœ¬æ·±åº¦åˆ†æ")
    print(f"{'='*70}\n")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # ç±»åˆ«åç§°
    class_names = [
        'butterfly', 'cat', 'chicken', 'cow', 'dog',
        'elephant', 'horse', 'sheep', 'spider', 'squirrel'
    ]
    
    # åŠ è½½æ¨¡å‹
    print(f"ğŸ“¥ åŠ è½½æ¨¡å‹...")
    model = get_model(
        model_name='resnet18',
        num_classes=10,
        pretrained=False,
        dropout=0.3,
        device=device
    )
    
    checkpoint = torch.load(args.checkpoint, map_location=device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ\n")
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    print("ğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®...")
    val_transform = get_val_transform()
    
    _, _, test_loader, class_to_idx = get_dataloaders(
        root_dir='../Animals-10',
        csv_file='train_test_val_split.csv',
        train_transform=val_transform,
        val_transform=val_transform,
        batch_size=32,
        num_workers=4,
        pin_memory=True
    )
    
    # è¯„ä¼°æ¨¡å‹
    print("\nğŸ“Š è¯„ä¼°æ¨¡å‹...")
    evaluator = Evaluator(
        model=model,
        device=device,
        class_names=class_names
    )
    
    results = evaluator.evaluate(test_loader, return_predictions=True)
    evaluator.print_results(results)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = '../outputs/error_analysis_deep'
    os.makedirs(output_dir, exist_ok=True)
    
    # è·å–é”™è¯¯æ ·æœ¬
    print(f"\n{'='*70}")
    print("ğŸ” æ”¶é›†é”™è¯¯æ ·æœ¬...")
    print(f"{'='*70}\n")
    
    misclassified = evaluator.get_misclassified_samples(test_loader)
    
    total_errors = sum(len(samples) for samples in misclassified.values())
    print(f"æ€»é”™è¯¯æ ·æœ¬æ•°: {total_errors}")
    print(f"é”™è¯¯ç±»å‹æ•°: {len(misclassified)}\n")
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = ErrorAnalyzer(
        class_names=class_names,
        save_dir=output_dir
    )
    
    # 1. ä¿å­˜é”™è¯¯æ ·æœ¬
    print("ğŸ’¾ ä¿å­˜é”™è¯¯æ ·æœ¬...")
    from data.dataset import AnimalDataset
    
    test_dataset = AnimalDataset(
        root_dir='../Animals-10',
        csv_file='train_test_val_split.csv',
        split='test',
        transform=val_transform,
        class_to_idx=class_to_idx
    )
    
    analyzer.save_misclassified_samples(
        misclassified=misclassified,
        dataset=test_dataset,
        max_samples_per_pair=20  # æ¯å¯¹æœ€å¤šä¿å­˜20ä¸ªæ ·æœ¬
    )
    
    # 2. å¯è§†åŒ–é”™è¯¯æ ·æœ¬
    print("\nğŸ–¼ï¸  å¯è§†åŒ–é”™è¯¯æ ·æœ¬...")
    analyzer.visualize_error_samples(
        misclassified=misclassified,
        top_k_pairs=5,
        samples_per_pair=8
    )
    
    # 3. ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\nğŸ“„ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    analyzer.generate_report(
        conf_matrix=results['confusion_matrix'],
        misclassified=misclassified
    )
    
    # 4. æ·±åº¦åˆ†æï¼šé’ˆå¯¹top-3æ··æ·†å¯¹
    print(f"\n{'='*70}")
    print("ğŸ§  æ·±åº¦åˆ†æTop-3æ··æ·†å¯¹")
    print(f"{'='*70}\n")
    
    top_confusion = analyzer.analyze_confusion_pairs(
        conf_matrix=results['confusion_matrix'],
        top_k=3
    )
    
    for rank, (true_cls, pred_cls, count) in enumerate(top_confusion, 1):
        print(f"\n{rank}. {true_cls} â†’ {pred_cls} ({count}ä¸ªæ ·æœ¬)")
        print("-" * 70)
        
        # æ‰¾åˆ°å¯¹åº”çš„é”™è¯¯æ ·æœ¬
        true_idx = class_names.index(true_cls)
        pred_idx = class_names.index(pred_cls)
        key = (true_idx, pred_idx)
        
        if key in misclassified:
            samples = misclassified[key]
            
            # è®¡ç®—å¹³å‡ç½®ä¿¡åº¦
            confidences = [s['confidence'] for s in samples]
            avg_conf = sum(confidences) / len(confidences)
            
            print(f"å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.2%}")
            print(f"æœ€é«˜ç½®ä¿¡åº¦: {max(confidences):.2%}")
            print(f"æœ€ä½ç½®ä¿¡åº¦: {min(confidences):.2%}")
            
            print(f"\nğŸ’¡ å¯èƒ½çš„åŸå› :")
            
            # åŸºäºç±»åˆ«ç‰¹ç‚¹ç»™å‡ºåˆ†æ
            if true_cls == 'cat' and pred_cls == 'dog':
                print("   - çŒ«å’Œç‹—çš„æ¯›å‘çº¹ç†ç›¸ä¼¼")
                print("   - å¯èƒ½æ˜¯ä¾§é¢æˆ–è¿œæ™¯ç…§ç‰‡ï¼Œç¼ºå°‘å…³é”®ç‰¹å¾ï¼ˆå¦‚è€³æœµå½¢çŠ¶ï¼‰")
                print("   - å»ºè®®: ä½¿ç”¨Grad-CAMæ£€æŸ¥æ¨¡å‹æ˜¯å¦å…³æ³¨äº†è€³æœµã€é¼»å­ç­‰åŒºåˆ†ç‰¹å¾")
            
            elif true_cls == 'butterfly' and pred_cls == 'spider':
                print("   - éƒ½æœ‰å¤šæ¡è…¿å’Œå¤æ‚çš„èº«ä½“ç»“æ„")
                print("   - å¯èƒ½æ˜¯å¾®è·ç…§ç‰‡ï¼ŒèƒŒæ™¯å¹²æ‰°")
                print("   - å»ºè®®: å¢åŠ æ•°æ®å¢å¼ºï¼Œç‰¹åˆ«æ˜¯èƒŒæ™¯å˜åŒ–")
            
            else:
                print(f"   - {true_cls}å’Œ{pred_cls}å¯èƒ½å­˜åœ¨è§†è§‰ç›¸ä¼¼æ€§")
                print(f"   - å»ºè®®æŸ¥çœ‹ä¿å­˜çš„é”™è¯¯æ ·æœ¬å›¾åƒè¿›è¡Œäººå·¥æ£€æŸ¥")
    
    print(f"\n{'='*70}")
    print("âœ… é”™è¯¯æ ·æœ¬åˆ†æå®Œæˆï¼")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"{'='*70}\n")
    
    print("\nğŸ“ åç»­å·¥ä½œå»ºè®®:")
    print("1. æŸ¥çœ‹ä¿å­˜çš„é”™è¯¯æ ·æœ¬å›¾åƒï¼Œäººå·¥æ£€æŸ¥æ˜¯å¦æœ‰æ ‡æ³¨é”™è¯¯")
    print("2. ä½¿ç”¨Grad-CAMå¯è§†åŒ–é”™è¯¯æ ·æœ¬ï¼Œçœ‹æ¨¡å‹å…³æ³¨å“ªé‡Œ")
    print("3. é’ˆå¯¹é«˜é¢‘æ··æ·†å¯¹ï¼Œè€ƒè™‘:")
    print("   - æ”¶é›†æ›´å¤šåŒºåˆ†æ€§æ ·æœ¬")
    print("   - è®¾è®¡ç‰¹å®šçš„æ•°æ®å¢å¼ºç­–ç•¥")
    print("   - è°ƒæ•´ç±»åˆ«æƒé‡")
    print()


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='é”™è¯¯æ ·æœ¬æ·±åº¦åˆ†æ')
    
    parser.add_argument(
        '--checkpoint',
        type=str,
        default='../outputs/exp1_baseline/models/best_model.pth',
        help='æ¨¡å‹checkpointè·¯å¾„'
    )
    
    args = parser.parse_args()
    
    if not os.path.exists(args.checkpoint):
        print(f"âŒ Checkpointä¸å­˜åœ¨: {args.checkpoint}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
        sys.exit(1)
    
    main(args)