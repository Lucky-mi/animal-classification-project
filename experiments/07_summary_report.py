"""
å®éªŒ7: ç»¼åˆæ±‡æ€»æŠ¥å‘Š
åŠŸèƒ½: ç”Ÿæˆæ‰€æœ‰æ¨¡å‹çš„å¯¹æ¯”å›¾è¡¨å’Œæ±‡æ€»æŠ¥å‘Š
ä½¿ç”¨æ–¹æ³•:
    python experiments/07_summary_report.py
"""

import os
import sys

# åˆ‡æ¢åˆ°projectç›®å½•ï¼Œç¡®ä¿ç›¸å¯¹è·¯å¾„æ­£ç¡®
script_dir = os.path.dirname(os.path.abspath(__file__))
project_dir = os.path.dirname(script_dir)
os.chdir(project_dir)
sys.path.append(project_dir)

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

from data import get_dataloaders, get_val_transform
from models import get_model
from utils import Evaluator

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def evaluate_model(model, test_loader, device, class_names):
    """è¯„ä¼°å•ä¸ªæ¨¡å‹ï¼Œè¿”å›è¯¦ç»†æŒ‡æ ‡"""
    model.eval()
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            outputs = model(images)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.numpy())

    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)

    # è®¡ç®—æ€»ä½“å‡†ç¡®ç‡
    accuracy = (all_preds == all_labels).mean() * 100

    # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å‡†ç¡®ç‡
    class_acc = {}
    for i, name in enumerate(class_names):
        mask = all_labels == i
        if mask.sum() > 0:
            class_acc[name] = (all_preds[mask] == all_labels[mask]).mean() * 100
        else:
            class_acc[name] = 0

    return accuracy, class_acc, all_preds, all_labels


def main():
    print(f"\n{'='*70}")
    print("ğŸ“Š å®éªŒ7: ç»¼åˆæ±‡æ€»æŠ¥å‘Š")
    print(f"{'='*70}\n")

    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"ä½¿ç”¨è®¾å¤‡: {device}\n")

    # ç±»åˆ«åç§°
    class_names = [
        'butterfly', 'cat', 'chicken', 'cow', 'dog',
        'elephant', 'horse', 'sheep', 'spider', 'squirrel'
    ]

    # æ¨¡å‹é…ç½®
    model_configs = [
        ('resnet18', '../outputs/exp1_baseline/models/best_model.pth', 'ResNet-18'),
        ('mobilenet_v2', '../outputs/exp1_mobilenet/models/best_model.pth', 'MobileNetV2'),
        ('resnet18', '../outputs/exp2.5_imbalance/models/best_model.pth', 'ResNet-18\n(W-Focal)'),
    ]

    # æ£€æŸ¥DeiTæ˜¯å¦å­˜åœ¨
    deit_path = '../outputs/exp1_deit/models/best_model.pth'
    if os.path.exists(deit_path):
        # æ£€æŸ¥æ˜¯å¦è®­ç»ƒå®Œæˆï¼ˆé€šè¿‡æ£€æŸ¥checkpointä¸­çš„epochï¼‰
        try:
            ckpt = torch.load(deit_path, map_location='cpu')
            if ckpt.get('epoch', 0) >= 25:  # è‡³å°‘è®­ç»ƒäº†25ä¸ªepoch
                model_configs.append(('deit_tiny', deit_path, 'DeiT-Tiny'))
                print("âœ… æ£€æµ‹åˆ°DeiT-Tinyæ¨¡å‹")
            else:
                print(f"âš ï¸ DeiT-Tinyåªè®­ç»ƒäº†{ckpt.get('epoch', 0)}ä¸ªepochï¼Œè·³è¿‡")
        except:
            pass

    # åŠ è½½æµ‹è¯•æ•°æ®
    print("ğŸ“¦ åŠ è½½æµ‹è¯•æ•°æ®...")
    val_transform = get_val_transform()

    use_pin_memory = torch.cuda.is_available()
    num_workers = 4 if torch.cuda.is_available() else 0

    _, _, test_loader, _ = get_dataloaders(
        root_dir='../Animals-10',
        csv_file='train_test_val_split.csv',
        train_transform=val_transform,
        val_transform=val_transform,
        batch_size=32,
        num_workers=num_workers,
        pin_memory=use_pin_memory
    )
    print("âœ… æ•°æ®åŠ è½½å®Œæˆ\n")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = '../outputs/summary_report'
    os.makedirs(output_dir, exist_ok=True)

    # è¯„ä¼°æ‰€æœ‰æ¨¡å‹
    results = {}

    for model_name, checkpoint_path, display_name in model_configs:
        print(f"\n{'-'*50}")
        print(f"ğŸ“¥ è¯„ä¼°æ¨¡å‹: {display_name.replace(chr(10), ' ')}")

        if not os.path.exists(checkpoint_path):
            print(f"âš ï¸ è·³è¿‡ - æ¨¡å‹ä¸å­˜åœ¨: {checkpoint_path}")
            continue

        # åŠ è½½æ¨¡å‹
        model = get_model(
            model_name=model_name,
            num_classes=10,
            pretrained=False,
            dropout=0.3,
            device=device
        )

        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        model.eval()

        # è¯„ä¼°
        accuracy, class_acc, preds, labels = evaluate_model(
            model, test_loader, device, class_names
        )

        results[display_name] = {
            'accuracy': accuracy,
            'class_acc': class_acc,
            'preds': preds,
            'labels': labels
        }

        print(f"   æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%")

        # æ¸…ç†æ˜¾å­˜
        del model
        if device == 'cuda':
            torch.cuda.empty_cache()

    if len(results) == 0:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
        return

    # ========== ç”Ÿæˆå›¾è¡¨ ==========

    print(f"\n{'='*50}")
    print("ğŸ“Š ç”Ÿæˆæ±‡æ€»å›¾è¡¨...")
    print(f"{'='*50}\n")

    model_names = list(results.keys())
    accuracies = [results[m]['accuracy'] for m in model_names]

    # å›¾1: æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(10, 6))
    colors = ['#3498db', '#2ecc71', '#e74c3c', '#9b59b6'][:len(model_names)]
    bars = ax.bar(model_names, accuracies, color=colors, edgecolor='black', linewidth=1.2)

    ax.set_ylabel('æµ‹è¯•å‡†ç¡®ç‡ (%)', fontsize=12)
    ax.set_title('æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax.set_ylim(85, 100)
    ax.grid(axis='y', alpha=0.3)

    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, acc in zip(bars, accuracies):
        ax.annotate(f'{acc:.2f}%',
                   xy=(bar.get_x() + bar.get_width() / 2, bar.get_height()),
                   xytext=(0, 5),
                   textcoords="offset points",
                   ha='center', va='bottom', fontsize=11, fontweight='bold')

    plt.tight_layout()
    save_path = os.path.join(output_dir, 'model_accuracy_comparison.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ’¾ ä¿å­˜: {save_path}")
    plt.close()

    # å›¾2: å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯”çƒ­åŠ›å›¾
    fig, ax = plt.subplots(figsize=(12, 8))

    # æ„å»ºæ•°æ®çŸ©é˜µ
    class_acc_matrix = []
    for m in model_names:
        row = [results[m]['class_acc'][c] for c in class_names]
        class_acc_matrix.append(row)

    class_acc_matrix = np.array(class_acc_matrix)

    im = ax.imshow(class_acc_matrix, cmap='RdYlGn', aspect='auto', vmin=70, vmax=100)

    ax.set_xticks(np.arange(len(class_names)))
    ax.set_yticks(np.arange(len(model_names)))
    ax.set_xticklabels(class_names, rotation=45, ha='right')
    ax.set_yticklabels([m.replace('\n', ' ') for m in model_names])

    # æ·»åŠ æ•°å€¼
    for i in range(len(model_names)):
        for j in range(len(class_names)):
            val = class_acc_matrix[i, j]
            color = 'white' if val < 85 else 'black'
            ax.text(j, i, f'{val:.1f}', ha='center', va='center', color=color, fontsize=9)

    ax.set_title('å„ç±»åˆ«å‡†ç¡®ç‡å¯¹æ¯” (%)', fontsize=14, fontweight='bold')
    plt.colorbar(im, ax=ax, label='å‡†ç¡®ç‡ (%)')

    plt.tight_layout()
    save_path = os.path.join(output_dir, 'class_accuracy_heatmap.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ’¾ ä¿å­˜: {save_path}")
    plt.close()

    # å›¾3: å„ç±»åˆ«å‡†ç¡®ç‡åˆ†ç»„æŸ±çŠ¶å›¾
    fig, ax = plt.subplots(figsize=(14, 6))

    x = np.arange(len(class_names))
    width = 0.8 / len(model_names)

    for i, m in enumerate(model_names):
        offset = (i - len(model_names)/2 + 0.5) * width
        values = [results[m]['class_acc'][c] for c in class_names]
        ax.bar(x + offset, values, width, label=m.replace('\n', ' '), color=colors[i])

    ax.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=12)
    ax.set_title('å„ç±»åˆ«å‡†ç¡®ç‡è¯¦ç»†å¯¹æ¯”', fontsize=14, fontweight='bold')
    ax.set_xticks(x)
    ax.set_xticklabels(class_names, rotation=45, ha='right')
    ax.legend(loc='lower right')
    ax.set_ylim(60, 105)
    ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    save_path = os.path.join(output_dir, 'class_accuracy_grouped_bar.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ’¾ ä¿å­˜: {save_path}")
    plt.close()

    # å›¾4: å°‘æ•°ç±» vs å¤šæ•°ç±»å¯¹æ¯”
    # å°‘æ•°ç±»: elephant, spider, squirrel (æ ·æœ¬å°‘)
    # å¤šæ•°ç±»: dog, spider, chicken (æ ·æœ¬å¤š)
    minority_classes = ['elephant', 'cat', 'squirrel', 'sheep']
    majority_classes = ['dog', 'spider', 'chicken', 'horse']

    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    for ax, (classes, title) in zip(axes, [(minority_classes, 'å°‘æ•°ç±»è¡¨ç°'),
                                            (majority_classes, 'å¤šæ•°ç±»è¡¨ç°')]):
        for i, m in enumerate(model_names):
            values = [results[m]['class_acc'][c] for c in classes]
            ax.bar(np.arange(len(classes)) + i*0.25, values, 0.25,
                   label=m.replace('\n', ' '), color=colors[i])

        ax.set_ylabel('å‡†ç¡®ç‡ (%)', fontsize=11)
        ax.set_title(title, fontsize=12, fontweight='bold')
        ax.set_xticks(np.arange(len(classes)) + 0.25)
        ax.set_xticklabels(classes, rotation=45, ha='right')
        ax.legend(fontsize=9)
        ax.set_ylim(70, 105)
        ax.grid(axis='y', alpha=0.3)

    plt.tight_layout()
    save_path = os.path.join(output_dir, 'minority_majority_comparison.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ’¾ ä¿å­˜: {save_path}")
    plt.close()

    # ========== ç”Ÿæˆæ–‡å­—æŠ¥å‘Š ==========

    report_path = os.path.join(output_dir, 'summary_report.txt')
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("Animal-10 å›¾åƒåˆ†ç±»å®éªŒæ±‡æ€»æŠ¥å‘Š\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 70 + "\n\n")

        f.write("ä¸€ã€æ¨¡å‹æµ‹è¯•å‡†ç¡®ç‡\n")
        f.write("-" * 70 + "\n")
        for m in model_names:
            f.write(f"{m.replace(chr(10), ' '):<25} {results[m]['accuracy']:.2f}%\n")

        f.write("\näºŒã€å„ç±»åˆ«å‡†ç¡®ç‡\n")
        f.write("-" * 70 + "\n")
        f.write(f"{'ç±»åˆ«':<12}" + "".join([f"{m.replace(chr(10), ' '):<18}" for m in model_names]) + "\n")
        f.write("-" * 70 + "\n")
        for c in class_names:
            row = f"{c:<12}"
            for m in model_names:
                row += f"{results[m]['class_acc'][c]:<18.2f}"
            f.write(row + "\n")

        f.write("\nä¸‰ã€ä¸»è¦å‘ç°\n")
        f.write("-" * 70 + "\n")

        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model = max(results.keys(), key=lambda m: results[m]['accuracy'])
        f.write(f"1. æœ€ä½³æ¨¡å‹: {best_model.replace(chr(10), ' ')} ({results[best_model]['accuracy']:.2f}%)\n")

        # æ‰¾å‡ºæœ€éš¾åˆ†ç±»çš„ç±»åˆ«
        avg_class_acc = {}
        for c in class_names:
            avg_class_acc[c] = np.mean([results[m]['class_acc'][c] for m in model_names])
        hardest_class = min(avg_class_acc.keys(), key=lambda c: avg_class_acc[c])
        f.write(f"2. æœ€éš¾åˆ†ç±»ç±»åˆ«: {hardest_class} (å¹³å‡å‡†ç¡®ç‡: {avg_class_acc[hardest_class]:.2f}%)\n")

        # æ‰¾å‡ºæœ€å®¹æ˜“åˆ†ç±»çš„ç±»åˆ«
        easiest_class = max(avg_class_acc.keys(), key=lambda c: avg_class_acc[c])
        f.write(f"3. æœ€æ˜“åˆ†ç±»ç±»åˆ«: {easiest_class} (å¹³å‡å‡†ç¡®ç‡: {avg_class_acc[easiest_class]:.2f}%)\n")

        f.write("\nå››ã€ç»“è®ºä¸å»ºè®®\n")
        f.write("-" * 70 + "\n")
        f.write("1. æ‰€æœ‰æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šéƒ½å–å¾—äº†è¾ƒå¥½çš„å‡†ç¡®ç‡ (>93%)\n")
        f.write("2. MobileNetV2åœ¨ä¿æŒè½»é‡åŒ–çš„åŒæ—¶è¾¾åˆ°äº†ä¸ResNet-18ç›¸å½“çš„æ€§èƒ½\n")
        f.write("3. Weighted Focal Losså¯¹å°‘æ•°ç±»çš„åˆ†ç±»æœ‰ä¸€å®šå¸®åŠ©\n")
        f.write("4. å»ºè®®åç»­å·¥ä½œ:\n")
        f.write("   - æ”¶é›†æ›´å¤šå°‘æ•°ç±»æ ·æœ¬\n")
        f.write("   - å°è¯•æ›´å¼ºçš„æ•°æ®å¢å¼º\n")
        f.write("   - ä½¿ç”¨é›†æˆå­¦ä¹ æå‡æ€§èƒ½\n")

    print(f"ğŸ’¾ ä¿å­˜æŠ¥å‘Š: {report_path}")

    print(f"\n{'='*70}")
    print("âœ… æ±‡æ€»æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“‚ ç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    main()
