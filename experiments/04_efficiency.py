"""
å®éªŒ4: æ¨¡å‹æ•ˆç‡å¯¹æ¯”
è´Ÿè´£äºº: B2
åŠŸèƒ½: å¯¹æ¯”ä¸åŒæ¨¡å‹çš„å‚æ•°é‡ã€FLOPsã€æ¨ç†é€Ÿåº¦
ä½¿ç”¨æ–¹æ³•:
    python experiments/04_efficiency.py
"""

import os
import sys
sys.path.append('..')

import torch
import time
import numpy as np
from thop import profile
import matplotlib.pyplot as plt

from models import get_model, count_parameters


def measure_inference_time(model, device, num_runs=100):
    """
    æµ‹é‡æ¨¡å‹æ¨ç†æ—¶é—´
    
    Args:
        model: æ¨¡å‹
        device: è®¾å¤‡
        num_runs: è¿è¡Œæ¬¡æ•°
    
    Returns:
        avg_time: å¹³å‡æ¨ç†æ—¶é—´(ms)
    """
    model.eval()
    
    # é¢„çƒ­
    dummy_input = torch.randn(1, 3, 224, 224).to(device)
    with torch.no_grad():
        for _ in range(10):
            _ = model(dummy_input)
    
    # æµ‹é‡
    times = []
    
    with torch.no_grad():
        for _ in range(num_runs):
            if device == 'cuda':
                torch.cuda.synchronize()
            
            start = time.time()
            _ = model(dummy_input)
            
            if device == 'cuda':
                torch.cuda.synchronize()
            
            end = time.time()
            times.append((end - start) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
    
    return np.mean(times), np.std(times)


def main():
    print(f"\n{'='*70}")
    print("âš¡ å®éªŒ4: æ¨¡å‹æ•ˆç‡å¯¹æ¯”")
    print(f"{'='*70}\n")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    model_names = ['resnet18', 'mobilenet_v2', 'deit_tiny']
    
    results = {
        'model': [],
        'params': [],
        'params_mb': [],
        'flops': [],
        'flops_g': [],
        'inference_time_mean': [],
        'inference_time_std': []
    }
    
    for model_name in model_names:
        print(f"\nğŸ“Š åˆ†ææ¨¡å‹: {model_name}")
        print("-" * 70)
        
        # åˆ›å»ºæ¨¡å‹
        model = get_model(
            model_name=model_name,
            num_classes=10,
            pretrained=False,
            dropout=0.3,
            device=device
        )
        
        # 1. å‚æ•°é‡
        total_params, trainable_params = count_parameters(model)
        params_mb = total_params * 4 / (1024 ** 2)  # å‡è®¾float32
        
        print(f"å‚æ•°é‡: {total_params:,} ({params_mb:.2f} MB)")
        
        # 2. FLOPs
        try:
            dummy_input = torch.randn(1, 3, 224, 224).to(device)
            flops, _ = profile(model, inputs=(dummy_input,), verbose=False)
            flops_g = flops / 1e9
            print(f"FLOPs: {flops_g:.2f} G")
        except Exception as e:
            print(f"âš ï¸ FLOPsè®¡ç®—å¤±è´¥: {e}")
            flops = 0
            flops_g = 0
        
        # 3. æ¨ç†é€Ÿåº¦
        print(f"æµ‹é‡æ¨ç†é€Ÿåº¦ (100æ¬¡è¿è¡Œ)...", end=' ')
        mean_time, std_time = measure_inference_time(model, device, num_runs=100)
        print(f"å®Œæˆ")
        print(f"æ¨ç†æ—¶é—´: {mean_time:.2f} Â± {std_time:.2f} ms")
        
        # ä¿å­˜ç»“æœ
        results['model'].append(model_name)
        results['params'].append(total_params)
        results['params_mb'].append(params_mb)
        results['flops'].append(flops)
        results['flops_g'].append(flops_g)
        results['inference_time_mean'].append(mean_time)
        results['inference_time_std'].append(std_time)
        
        # æ¸…ç†æ˜¾å­˜
        del model
        if device == 'cuda':
            torch.cuda.empty_cache()
    
    # ç”Ÿæˆå¯¹æ¯”å›¾
    output_dir = '../outputs/efficiency_analysis'
    os.makedirs(output_dir, exist_ok=True)
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # å‚æ•°é‡å¯¹æ¯”
    axes[0].bar(results['model'], results['params_mb'], color='skyblue')
    axes[0].set_ylabel('Parameters (MB)', fontsize=12)
    axes[0].set_title('Model Size Comparison', fontsize=14)
    axes[0].set_xticklabels(results['model'], rotation=45)
    
    # FLOPså¯¹æ¯”
    axes[1].bar(results['model'], results['flops_g'], color='lightcoral')
    axes[1].set_ylabel('FLOPs (G)', fontsize=12)
    axes[1].set_title('Computational Cost Comparison', fontsize=14)
    axes[1].set_xticklabels(results['model'], rotation=45)
    
    # æ¨ç†é€Ÿåº¦å¯¹æ¯”
    axes[2].bar(results['model'], results['inference_time_mean'], 
                yerr=results['inference_time_std'], color='lightgreen', capsize=5)
    axes[2].set_ylabel('Inference Time (ms)', fontsize=12)
    axes[2].set_title('Inference Speed Comparison', fontsize=14)
    axes[2].set_xticklabels(results['model'], rotation=45)
    
    plt.tight_layout()
    save_path = os.path.join(output_dir, 'model_efficiency_comparison.png')
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"\nğŸ’¾ æ•ˆç‡å¯¹æ¯”å›¾ä¿å­˜è‡³: {save_path}")
    plt.close()
    
    # ç”ŸæˆæŠ¥å‘Š
    report_path = os.path.join(output_dir, 'efficiency_report.txt')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("æ¨¡å‹æ•ˆç‡å¯¹æ¯”æŠ¥å‘Š\n")
        f.write("=" * 70 + "\n\n")
        
        f.write(f"{'æ¨¡å‹':<15} {'å‚æ•°é‡(M)':<12} {'FLOPs(G)':<12} {'æ¨ç†æ—¶é—´(ms)':<15}\n")
        f.write("-" * 70 + "\n")
        
        for i, model_name in enumerate(results['model']):
            f.write(f"{model_name:<15} "
                   f"{results['params'][i]/1e6:<12.2f} "
                   f"{results['flops_g'][i]:<12.2f} "
                   f"{results['inference_time_mean'][i]:<15.2f}\n")
        
        f.write("\n" + "=" * 70 + "\n\n")
        
        f.write("ğŸ’¡ åˆ†æå»ºè®®:\n\n")
        
        # æ‰¾åˆ°æœ€å¿«çš„æ¨¡å‹
        fastest_idx = np.argmin(results['inference_time_mean'])
        fastest_model = results['model'][fastest_idx]
        
        f.write(f"1. é€Ÿåº¦æœ€å¿«: {fastest_model}\n")
        f.write(f"   æ¨ç†æ—¶é—´: {results['inference_time_mean'][fastest_idx]:.2f} ms\n")
        f.write(f"   é€‚ç”¨åœºæ™¯: ç§»åŠ¨ç«¯éƒ¨ç½²ã€å®æ—¶åº”ç”¨\n\n")
        
        # æ‰¾åˆ°å‚æ•°é‡æœ€å°çš„æ¨¡å‹
        lightest_idx = np.argmin(results['params'])
        lightest_model = results['model'][lightest_idx]
        
        f.write(f"2. æœ€è½»é‡: {lightest_model}\n")
        f.write(f"   å‚æ•°é‡: {results['params_mb'][lightest_idx]:.2f} MB\n")
        f.write(f"   é€‚ç”¨åœºæ™¯: å­˜å‚¨å—é™è®¾å¤‡\n\n")
        
        f.write(f"3. æ€§èƒ½æƒè¡¡:\n")
        f.write(f"   - å¦‚æœè¿½æ±‚å‡†ç¡®ç‡ï¼Œé€‰æ‹©ResNet-18\n")
        f.write(f"   - å¦‚æœè¿½æ±‚é€Ÿåº¦ï¼Œé€‰æ‹©MobileNetV2\n")
        f.write(f"   - å¦‚æœå¸Œæœ›å¹³è¡¡ï¼Œæ ¹æ®å®é™…éœ€æ±‚å†³å®š\n")
    
    print(f"ğŸ’¾ æ•ˆç‡æŠ¥å‘Šä¿å­˜è‡³: {report_path}")
    
    print(f"\n{'='*70}")
    print("âœ… æ•ˆç‡åˆ†æå®Œæˆï¼")
    print(f"{'='*70}\n")


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†thop
    try:
        import thop
    except ImportError:
        print("âŒ è¯·å…ˆå®‰è£…thopåº“: pip install thop")
        sys.exit(1)
    
    main()