"""
æ¨¡å‹å·¥å‚
è´Ÿè´£äºº: B2
åŠŸèƒ½: ç»Ÿä¸€æ¥å£è·å–ä¸åŒæ¨¡å‹ï¼ˆResNet-18, MobileNetV2, DeiT-Tinyï¼‰
"""

import torch
import torch.nn as nn
import torchvision.models as models
import timm
from torchinfo import summary
from typing import Tuple


def get_model(
    model_name: str,
    num_classes: int = 10,
    pretrained: bool = True,
    dropout: float = 0.3,
    device: str = 'cuda'
) -> nn.Module:
    """
    è·å–æ¨¡å‹
    
    Args:
        model_name: æ¨¡å‹åç§°
            - 'resnet18': ResNet-18 (ç»å…¸CNN)
            - 'mobilenet_v2': MobileNetV2 (è½»é‡çº§CNN)
            - 'deit_tiny': DeiT-Tiny (è½»é‡çº§Transformer)
        num_classes: åˆ†ç±»æ•°é‡
        pretrained: æ˜¯å¦ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡
        dropout: Dropoutæ¯”ä¾‹
        device: è®¾å¤‡
    
    Returns:
        model: æ¨¡å‹å®ä¾‹
    """
    
    print(f"\n{'='*60}")
    print(f"ğŸ”§ åˆ›å»ºæ¨¡å‹: {model_name}")
    print(f"   é¢„è®­ç»ƒ: {pretrained}")
    print(f"   ç±»åˆ«æ•°: {num_classes}")
    print(f"   Dropout: {dropout}")
    print(f"{'='*60}\n")
    
    if model_name == 'resnet18':
        # ResNet-18 (ç»å…¸åŸºçº¿)
        if pretrained:
            weights = models.ResNet18_Weights.IMAGENET1K_V1
            model = models.resnet18(weights=weights)
        else:
            model = models.resnet18(weights=None)
        
        # ä¿®æ”¹æœ€åçš„å…¨è¿æ¥å±‚
        num_features = model.fc.in_features
        model.fc = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(num_features, num_classes)
        )
    
    elif model_name == 'mobilenet_v2':
        # MobileNetV2 (è½»é‡çº§)
        if pretrained:
            weights = models.MobileNet_V2_Weights.IMAGENET1K_V1
            model = models.mobilenet_v2(weights=weights)
        else:
            model = models.mobilenet_v2(weights=None)
        
        # ä¿®æ”¹åˆ†ç±»å™¨
        num_features = model.classifier[1].in_features
        model.classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(num_features, num_classes)
        )
    
    elif model_name == 'deit_tiny':
        # DeiT-Tiny (Data-efficient Image Transformer)
        # ä½¿ç”¨timmåº“
        if pretrained:
            model = timm.create_model('deit_tiny_patch16_224', pretrained=True, num_classes=num_classes)
        else:
            model = timm.create_model('deit_tiny_patch16_224', pretrained=False, num_classes=num_classes)
        
        # DeiTå·²ç»æœ‰å†…ç½®çš„dropoutï¼Œå¯ä»¥è°ƒæ•´
        if hasattr(model, 'head_drop'):
            model.head_drop = nn.Dropout(dropout)
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ¨¡å‹åç§°: {model_name}")
    
    model = model.to(device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    print_model_info(model, model_name, device)
    
    return model


def print_model_info(model: nn.Module, model_name: str, device: str):
    """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
    try:
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"ğŸ“Š {model_name} æ¨¡å‹ç»Ÿè®¡:")
        print(f"   æ€»å‚æ•°é‡: {total_params:,}")
        print(f"   å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        print(f"   å‚æ•°é‡(MB): {total_params * 4 / 1024 / 1024:.2f}")
        
        # ä½¿ç”¨torchinfoæ‰“å°è¯¦ç»†ä¿¡æ¯
        summary(model, input_size=(1, 3, 224, 224), device=device, verbose=0)
        
    except Exception as e:
        print(f"âš ï¸ æ— æ³•æ‰“å°æ¨¡å‹è¯¦ç»†ä¿¡æ¯: {e}")


def count_parameters(model: nn.Module) -> Tuple[int, int]:
    """
    ç»Ÿè®¡æ¨¡å‹å‚æ•°é‡
    
    Returns:
        total_params: æ€»å‚æ•°é‡
        trainable_params: å¯è®­ç»ƒå‚æ•°é‡
    """
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total_params, trainable_params


def get_model_flops(model: nn.Module, input_size: Tuple[int, int, int, int] = (1, 3, 224, 224)) -> float:
    """
    è®¡ç®—æ¨¡å‹FLOPs (éœ€è¦å®‰è£…thopåº“)
    
    Args:
        model: æ¨¡å‹
        input_size: è¾“å…¥å°ºå¯¸ (batch, channels, height, width)
    
    Returns:
        flops: FLOPsæ•°é‡
    """
    try:
        from thop import profile
        
        device = next(model.parameters()).device
        dummy_input = torch.randn(input_size).to(device)
        
        flops, params = profile(model, inputs=(dummy_input,), verbose=False)
        
        return flops
    
    except ImportError:
        print("âš ï¸ éœ€è¦å®‰è£…thopåº“æ¥è®¡ç®—FLOPs: pip install thop")
        return 0.0


if __name__ == "__main__":
    # æµ‹è¯•æ‰€æœ‰æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    model_names = ['resnet18', 'mobilenet_v2', 'deit_tiny']
    
    for name in model_names:
        print(f"\n{'='*80}")
        model = get_model(
            model_name=name,
            num_classes=10,
            pretrained=True,
            dropout=0.3,
            device=device
        )
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        dummy_input = torch.randn(2, 3, 224, 224).to(device)
        output = model(dummy_input)
        print(f"\nâœ… è¾“å…¥: {dummy_input.shape} -> è¾“å‡º: {output.shape}")
        
        del model
        torch.cuda.empty_cache()
    
    print(f"\n{'='*80}")
    print("âœ… æ‰€æœ‰æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")